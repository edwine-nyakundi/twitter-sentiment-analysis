{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDRnR0LoD0hX",
        "outputId": "b6a789af-d464-4e52-a0e7-786f837e8c67"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\LYZ\\AppData\\Local\\Programs\\Python\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/LYZ/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/train.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69duoC0zD82J",
        "outputId": "7b13a6e4-6692-4779-8e05-fc23c0f25cd6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\LYZ\\AppData\\Local\\Programs\\Python\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/LYZ/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters, links, and user mentions\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub('@[^\\s]+', '', text)\n",
        "    text = re.sub(r'#', '', text)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Remove stop words, punctuation, and special characters\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to the 'tweet' column\n",
        "df['cleaned_tweet'] = df['tweet'].apply(preprocess_text)\n",
        "\n",
        "# Save the preprocessed dataset\n",
        "df.to_csv('preprocessed_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLWCePfCEv4k"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\LYZ\\AppData\\Local\\Programs\\Python\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/LYZ/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Create a Bag-of-Words model\n",
        "vectorizer_bow = CountVectorizer(max_features=5000)\n",
        "X_bow = vectorizer_bow.fit_transform(df['cleaned_tweet'])\n",
        "\n",
        "# Save the BoW feature matrix\n",
        "pd.DataFrame(X_bow.toarray(), columns=vectorizer_bow.get_feature_names_out()).to_csv('bow_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nW-cTO7FK5f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\LYZ\\AppData\\Local\\Programs\\Python\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/LYZ/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create a TF-IDF model\n",
        "vectorizer_tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(df['cleaned_tweet'])\n",
        "\n",
        "# Save the TF-IDF feature matrix\n",
        "pd.DataFrame(X_tfidf.toarray(), columns=vectorizer_tfidf.get_feature_names_out()).to_csv('tfidf_features.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu-nF7m3FMRg",
        "outputId": "ed6b7255-d87e-49fa-81a4-39890a773455"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\LYZ\\AppData\\Local\\Programs\\Python\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/LYZ/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bow, df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c84ogOX5KC3B",
        "outputId": "25e740b2-8e4a-4f8d-a2d2-da29bf9b4731"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\LYZ\\AppData\\Local\\Programs\\Python\\Python312\\python.exe' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/LYZ/AppData/Local/Programs/Python/Python312/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create a TF-IDF model\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(df['cleaned_tweet'])\n",
        "\n",
        "# Split the dataset for TF-IDF\n",
        "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Logistic Regression model with TF-IDF features\n",
        "model_tfidf = LogisticRegression()\n",
        "model_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model with TF-IDF features\n",
        "accuracy_tfidf = accuracy_score(y_test_tfidf, y_pred_tfidf)\n",
        "precision_tfidf = precision_score(y_test_tfidf, y_pred_tfidf)\n",
        "recall_tfidf = recall_score(y_test_tfidf, y_pred_tfidf)\n",
        "f1_tfidf = f1_score(y_test_tfidf, y_pred_tfidf)\n",
        "\n",
        "# Print evaluation metrics for TF-IDF\n",
        "print(\"\\nTF-IDF Feature Extraction:\")\n",
        "print(f\"Accuracy: {accuracy_tfidf:.4f}\")\n",
        "print(f\"Precision: {precision_tfidf:.4f}\")\n",
        "print(f\"Recall: {recall_tfidf:.4f}\")\n",
        "print(f\"F1 Score: {f1_tfidf:.4f}\")\n",
        "\n",
        "# Comparative Analysis\n",
        "print(\"\\nComparative Analysis:\")\n",
        "print(\"BoW                    vs           TF-IDF\")\n",
        "print(f\"Accuracy -> BoW: {accuracy:.4f}       TF-IDF: {accuracy_tfidf:.4f}\")\n",
        "print(f\"Precision -> BoW: {precision:.4f}     TF-IDF: {precision_tfidf:.4f}\")\n",
        "print(f\"Recall -> BoW: {recall:.4f}          TF-IDF: {recall_tfidf:.4f}\")\n",
        "print(f\"F1 Score -> BoW: {f1:.4f}           TF-IDF: {f1_tfidf:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
